{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53cd899e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: groq in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (0.30.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from groq) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from groq) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from groq) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from datasets) (2.3.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: xxhash in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from datasets) (0.34.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\myu32\\anaconda3\\envs\\ybigta\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install groq python-dotenv numpy tqdm datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "249253df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import random\n",
    "import pprint\n",
    "\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "load_dotenv()\n",
    "random.seed(0)\n",
    "\n",
    "client = Groq()\n",
    "gsm8k_dataset = load_dataset(\"gsm8k\", \"main\")\n",
    "\n",
    "gsm8k_train = gsm8k_dataset[\"train\"]\n",
    "gsm8k_test  = gsm8k_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4d75bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response_using_Llama(\n",
    "        prompt: str,\n",
    "        model: str = \"llama3-8b-8192\"\n",
    "    ):\n",
    "    try:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant that solves math problems.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "            model=model,\n",
    "            temperature=0.3, ### ìˆ˜ì •í•´ë„ ë©ë‹ˆë‹¤!\n",
    "            stream=False\n",
    "        )\n",
    "        return chat_completion.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"API call error: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef65ad3",
   "metadata": {},
   "source": [
    "#### ì‘ë‹µ ì˜ ë‚˜ì˜¤ëŠ”ì§€ í™•ì¸í•´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a37fad9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there! I'm excited to help you with any math problems you might have. What kind of math are you working on? Do you have a specific problem you're stuck on or a concept you're trying to understand? Let me know and I'll do my best to assist you!\n"
     ]
    }
   ],
   "source": [
    "response = generate_response_using_Llama(\n",
    "    prompt=\"Hello world!\",\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988803ae",
   "metadata": {},
   "source": [
    "#### GSM8K ë°ì´í„°ì…‹ í™•ì¸í•´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbd177eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Question]\n",
      "Janetâ€™s ducks lay 16 eggs per day\n",
      " She eats three for breakfast every morning and bakes muffins for her friends every day with four\n",
      " She sells the remainder at the farmers' market daily for $2 per fresh duck egg\n",
      " How much in dollars does she make every day at the farmers' market?\n",
      "====================================================================================================\n",
      "[Answer]\n",
      "Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eggs a day.\n",
      "She makes 9 * 2 = $<<9*2=18>>18 every day at the farmerâ€™s market.\n",
      "#### 18\n"
     ]
    }
   ],
   "source": [
    "print(\"[Question]\")\n",
    "for l in gsm8k_test['question'][0].split(\".\"):\n",
    "    print(l)\n",
    "print(\"=\"*100)\n",
    "print(\"[Answer]\")\n",
    "print(gsm8k_test['answer'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaabe66c",
   "metadata": {},
   "source": [
    "#### Util í•¨ìˆ˜ë“¤\n",
    "- extract_final_answer: LLMì˜ ì‘ë‹µì„ parseí•˜ì—¬ ìµœì¢… ê²°ê³¼ë§Œ ì¶”ì¶œ (ì •ë‹µê³¼ ë¹„êµí•˜ê¸° ìœ„í•´)\n",
    "- run_benchmark_test: ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸\n",
    "- save_final_result: ê²°ê³¼ë¬¼ ì œì¶œì„ ìœ„í•œ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40c10811",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ìˆ˜ì •í•´ë„ ë©ë‹ˆë‹¤!\n",
    "def extract_final_answer(response: str):\n",
    "    regex = r\"(?:Answer:|Model response:)\\s*\\$?([0-9,]+)\\b|([0-9,]+)\\s*(meters|cups|miles|minutes)\"\n",
    "    matches = re.finditer(regex, response, re.MULTILINE)\n",
    "    results = [match.group(1) if match.group(1) else match.group(2).replace(\",\", \"\") for match in matches]\n",
    "\n",
    "    if len(results) == 0:\n",
    "        additional_regex = r\"\\$?([0-9,]+)\"\n",
    "        additional_matches = re.finditer(additional_regex, response, re.MULTILINE)\n",
    "        results.extend([match.group(1).replace(\",\", \"\") for match in additional_matches])\n",
    "\n",
    "    return results[-1] if results else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e3a05ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ìˆ˜ì •í•´ë„ ë©ë‹ˆë‹¤!\n",
    "def run_benchmark_test(\n",
    "        dataset,\n",
    "        prompt: str,\n",
    "        model: str = \"llama3-8b-8192\",\n",
    "        num_samples: int = 50,\n",
    "        VERBOSE: bool = False\n",
    "    ):\n",
    "    correct = 0\n",
    "    total   = 0\n",
    "    results = []\n",
    "\n",
    "    for i in tqdm(range(min(num_samples, len(dataset)))):\n",
    "        question = dataset[i][\"question\"]\n",
    "        correct_answer = float(re.findall(r'\\d+(?:\\.\\d+)?', dataset[i][\"answer\"].split('####')[-1])[0])\n",
    "\n",
    "        response = generate_response_using_Llama(\n",
    "            prompt=prompt.format(question=question),\n",
    "            model=model\n",
    "        )\n",
    "\n",
    "        if response:\n",
    "            if VERBOSE:\n",
    "                print(\"=\"*50)\n",
    "                print(response)\n",
    "                print(\"=\"*50)\n",
    "            predicted_answer = extract_final_answer(response)\n",
    "\n",
    "            if isinstance(predicted_answer, str):\n",
    "                predicted_answer = float(predicted_answer.replace(\",\", \"\"))\n",
    "            \n",
    "            diff = abs(predicted_answer - correct_answer)\n",
    "            is_correct = diff < 1e-5 if predicted_answer is not None else False\n",
    "            \n",
    "            if is_correct:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "            \n",
    "            results.append({\n",
    "                'question': question,\n",
    "                'correct_answer': correct_answer,\n",
    "                'predicted_answer': predicted_answer,\n",
    "                'response': response,\n",
    "                'correct': is_correct\n",
    "            })\n",
    "\n",
    "            if (i + 1) % 5 == 0:\n",
    "                current_acc = correct/total if total > 0 else 0\n",
    "                print(f\"Progress: [{i+1}/{num_samples}]\")\n",
    "                print(f\"Current Acc.: [{current_acc:.2%}]\")\n",
    "\n",
    "    return results, correct/total if total > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e63f5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_final_result(results: List[Dict[str, Any]], accuracy: float, filename: str) -> None:\n",
    "    result_str = f\"====== ACCURACY: {accuracy} ======\\n\\n\"\n",
    "    result_str += f\"[Details]\\n\"\n",
    "    \n",
    "    for idx, result in enumerate(results):\n",
    "        result_str += f\"Question {idx+1}: {result['question']}\\n\"\n",
    "        result_str += f\"Correct Answer: {result['correct_answer']}\\n\"\n",
    "        result_str += f\"Predicted Answer: {result['predicted_answer']}\\n\"\n",
    "        result_str += f\"Correct: {result['correct']}\\n\\n\"\n",
    "    \n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(result_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c498f9ed",
   "metadata": {},
   "source": [
    "#### Direct prompting with few-shot example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f430083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_direct_prompt(num_examples: int = 3) -> str:\n",
    "    train_dataset = gsm8k_train\n",
    "\n",
    "    sampled_indices = random.sample(\n",
    "        [i for i in range(len(train_dataset['question']))],\n",
    "        num_examples\n",
    "    )\n",
    "\n",
    "    prompt = \"Instruction:\\nSolve the following mathematical question and generate ONLY the answer after a tag, 'Answer:' without any rationale.\\n\"\n",
    "\n",
    "    for i in range(num_examples):\n",
    "        cur_question = train_dataset['question'][i]\n",
    "        cur_answer = train_dataset['answer'][i].split(\"####\")[-1].strip()\n",
    "\n",
    "        prompt += f\"\\n[Example {i+1}]\\n\"\n",
    "        prompt += f\"Question:\\n{cur_question}\\n\"\n",
    "        prompt += f\"Answer:{cur_answer}\\n\"\n",
    "\n",
    "    prompt += \"\\nQuestion:\\n{question}\\nAnswer:\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68a2b484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:02<00:02,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/10]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/10]\n",
      "Current Acc.: [30.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ì €ì¥ë˜ëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”!\n",
    "PROMPT = construct_direct_prompt(3)\n",
    "VERBOSE = False\n",
    "\n",
    "results, accuracy = run_benchmark_test(\n",
    "    dataset=gsm8k_test,\n",
    "    prompt=PROMPT,\n",
    "    VERBOSE=VERBOSE,\n",
    "    num_samples=10\n",
    ")\n",
    "save_final_result(results, accuracy, \"example.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41874896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0shot ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ ì‹œì‘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 5/50 [00:03<00:28,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 10/50 [00:07<00:32,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 15/50 [00:10<00:23,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [13.33%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [00:13<00:15,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [00:24<00:54,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [00:37<00:51,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [00:51<00:41,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [17.14%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [01:05<00:26,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [15.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [01:18<00:13,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [15.56%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [01:32<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [18.00%]\n",
      "3shot ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ ì‹œì‘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 5/50 [00:12<01:55,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 10/50 [00:26<01:54,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [30.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 15/50 [00:39<01:37,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [00:53<01:24,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [01:07<01:09,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [01:20<00:53,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [01:33<00:38,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [17.14%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [01:47<00:27,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [15.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [02:01<00:13,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [17.78%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [02:14<00:00,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [20.00%]\n",
      "5shot ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ ì‹œì‘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 5/50 [00:11<01:51,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [40.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 10/50 [00:29<02:24,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 15/50 [00:42<01:38,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [13.33%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [00:55<01:20,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [01:07<01:03,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [24.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [01:21<00:53,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [23.33%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [01:34<00:39,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [01:47<00:23,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [17.50%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [01:58<00:12,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [15.56%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [02:12<00:00,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [16.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: 0 shot, 3 shot, 5 shot direct promptingì„ í†µí•´ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ë¥¼ í•œ í›„, ê°ê° direct_prompting_{shot: int}.txtë¡œ ì €ì¥í•´ì£¼ì„¸ìš”!\n",
    "# ì˜ˆì‹œ: shotì´ 5ì¸ ê²½ìš° direct_prompting_5.txt\n",
    "# í•­ìƒ num_samples=50 ì…ë‹ˆë‹¤!\n",
    "shots = [0, 3, 5]\n",
    "\n",
    "for shot in shots:\n",
    "    print(f\"{shot}shot ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ ì‹œì‘\")\n",
    "    PROMPT = construct_direct_prompt(shot)\n",
    "    VERBOSE = False\n",
    "\n",
    "    results, accuracy = run_benchmark_test(\n",
    "        dataset=gsm8k_test,\n",
    "        prompt=PROMPT,\n",
    "        VERBOSE=VERBOSE,\n",
    "        num_samples=50\n",
    "    )\n",
    "    save_final_result(results, accuracy, f\"direct_prompting_{shot}.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fd21d1",
   "metadata": {},
   "source": [
    "### Chain-of-Thought prompting with few-shot example\n",
    "```text\n",
    "[Question]\n",
    "Janetâ€™s ducks lay 16 eggs per day\n",
    " She eats three for breakfast every morning and bakes muffins for her friends every day with four\n",
    " She sells the remainder at the farmers' market daily for $2 per fresh duck egg\n",
    " How much in dollars does she make every day at the farmers' market?\n",
    "====================================================================================================\n",
    "[Answer]\n",
    "Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eggs a day.\n",
    "She makes 9 * 2 = $<<9*2=18>>18 every day at the farmerâ€™s market.\n",
    "#### 18\n",
    "```\n",
    "\n",
    "[Answer] ì•„ë˜ì˜ ì •ë‹µì„ ë„ì¶œí•˜ëŠ” ê³¼ì •ì„ ì˜ˆì‹œë¡œ ë‹¬ì•„ì£¼ë©´ CoTì˜ few shotì´ ë˜ê² ì£ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73a989e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_CoT_prompt(num_examples: int = 3) -> str:\n",
    "    train_dataset = gsm8k_train\n",
    "\n",
    "    sampled_indices = random.sample(\n",
    "        [i for i in range(len(train_dataset['question']))],\n",
    "        num_examples\n",
    "    )\n",
    "    prompt = \"Solve step-by-step. Answer after '####'.\\n\"  # ê°„ê²°í•œ instruction\n",
    "\n",
    "    for i in range(num_examples):\n",
    "        # ê°„ê²°í•œ CoT example í˜•ì‹\n",
    "        cur_q = train_dataset['question'][sampled_indices[i]].strip()\n",
    "        ans = train_dataset['answer'][sampled_indices[i]]\n",
    "        rationale = ans.split(\"####\")[0].strip().replace(\"\\n\", \" \")\n",
    "        final = ans.split(\"####\")[-1].strip()\n",
    "        \n",
    "        prompt += f\"Q: {cur_q}\\nA: {rationale}\\n#### {final}\\n\"\n",
    "\n",
    "    prompt += \"\\nQuestion:\\n{question}\\nAnswer:\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c510586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-shot CoT Prompting í…ŒìŠ¤íŠ¸ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 5/50 [00:04<00:32,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 10/50 [00:07<00:26,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 15/50 [00:11<00:27,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [00:15<00:24,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [55.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [00:17<00:14,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [52.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [00:35<01:18,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [53.33%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [00:42<00:24,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [01:00<00:24,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [55.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [01:25<00:22,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [57.78%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [01:33<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [58.00%]\n",
      "3-shot CoT Prompting í…ŒìŠ¤íŠ¸ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 5/50 [00:37<06:10,  8.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 10/50 [01:29<06:44, 10.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 15/50 [02:20<06:02, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [66.67%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [03:11<05:10, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [65.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [04:01<04:02,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [64.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [04:51<03:12,  9.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [66.67%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [05:39<02:22,  9.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [71.43%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [06:30<01:49, 10.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [65.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [07:17<00:49,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [68.89%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [08:06<00:00,  9.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [70.00%]\n",
      "5-shot CoT Prompting í…ŒìŠ¤íŠ¸ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 5/50 [00:55<08:24, 11.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 10/50 [01:56<07:55, 11.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 15/50 [02:58<07:01, 12.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [66.67%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [03:57<05:58, 11.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [70.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [04:57<04:49, 11.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [64.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [05:54<03:45, 11.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [70.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [06:51<02:33, 10.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [74.29%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [07:52<02:00, 12.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [67.50%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [08:49<00:55, 11.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [71.11%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [09:49<00:00, 11.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [70.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: 0 shot, 3 shot, 5 shot CoT promptingì„ í†µí•´ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ë¥¼ í•œ í›„, ê°ê° CoT_prompting_{shot: int}.txtë¡œ ì €ì¥í•´ì£¼ì„¸ìš”!\n",
    "# ì˜ˆì‹œ: shotì´ 5ì¸ ê²½ìš° CoT_prompting_5.txt\n",
    "# í•­ìƒ num_samples=50 ì…ë‹ˆë‹¤!\n",
    "\n",
    "\n",
    "shots = [0, 3, 5]\n",
    "\n",
    "for shot in shots:\n",
    "    print(f\"{shot}-shot CoT Prompting í…ŒìŠ¤íŠ¸ ì¤‘...\")\n",
    "    PROMPT = construct_CoT_prompt(shot)\n",
    "    VERBOSE = False\n",
    "\n",
    "    results, accuracy = run_benchmark_test(\n",
    "        dataset=gsm8k_test,\n",
    "        prompt=PROMPT,\n",
    "        VERBOSE=VERBOSE,\n",
    "        num_samples=50\n",
    "    )\n",
    "    save_final_result(results, accuracy, f\"CoT_prompting_{shot}.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c45b54",
   "metadata": {},
   "source": [
    "### Construct your prompt!!\n",
    "\n",
    "ëª©í‘œ: ë³¸ì¸ë§Œì˜ í”„ë¡¬í”„íŠ¸ë¥¼ í†µí•´ ì •ë‹µë¥ ì„ ë” ëŒì–´ì˜¬ë ¤ë³´ê¸°!\n",
    "- gsm8kì˜ train ë°ì´í„°ì…‹ì—ì„œ ì˜ˆì‹œë¥¼ ê°€ì ¸ì˜¨ ë‹¤ìŒ (ììœ ë¡­ê²Œ!)\n",
    "- ê·¸ ì˜ˆì‹œë“¤ì— ëŒ€í•œ í’€ì´ ê³¼ì •ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”!\n",
    "- ëª¨ë“  ê²ƒë“¤ì´ ììœ ì…ë‹ˆë‹¤! Direct Prompting, CoT Promptingì„ í•œ ê²°ê³¼ë³´ë‹¤ ì •ë‹µë¥ ë§Œ ë†’ìœ¼ë©´ ë¼ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09062c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from groq import Groq\n",
    "\n",
    "def construct_my_prompt(num_examples: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    ë‚´ í”„ë¡¬í”„íŠ¸ - ì¿¼í„° ì ˆì•½ì„ ìœ„í•´ ìµœì í™”\n",
    "    \n",
    "    Args:\n",
    "        num_examples: few-shot example ê°œìˆ˜ (0, 3, 5)\n",
    "    \n",
    "    Returns:\n",
    "        í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´\n",
    "    \"\"\"\n",
    "    import random\n",
    "    train_dataset = gsm8k_train\n",
    "    sampled_indices = random.sample(range(len(train_dataset[\"question\"])), \n",
    "                                   num_examples)\n",
    "\n",
    "    # ê°„ê²°í•œ instruction\n",
    "    prompt = \"Solve step-by-step. Use 'â†’' for steps. Answer after '####'.\\n\"\n",
    "\n",
    "    for i, idx in enumerate(sampled_indices):\n",
    "        question = train_dataset[\"question\"][idx].strip()\n",
    "        rationale = train_dataset[\"answer\"][idx].split(\"####\")[0].strip().replace('\\n', ' ')\n",
    "        answer = train_dataset[\"answer\"][idx].split(\"####\")[-1].strip()\n",
    "\n",
    "        # ìˆ˜ì‹ ê°•ì¡°\n",
    "        rationale = rationale.replace(\"So\", \"â†’\").replace(\".\", \". \")\n",
    "\n",
    "        # ê°„ê²°í•œ Q/A í˜•ì‹\n",
    "        prompt += f\"Q: {question}\\nA: {rationale}\\n#### {answer}\\n\"\n",
    "\n",
    "    prompt += \"Q: {question}\\nA:\"\n",
    "    return prompt\n",
    "\n",
    "def check_quota_usage():\n",
    "    \"\"\"\n",
    "    í˜„ì¬ ì¿¼í„° ì‚¬ìš©ëŸ‰ í™•ì¸\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = Groq()\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": \"test\"}],\n",
    "            model=\"llama3-8b-8192\",\n",
    "            max_tokens=1\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        if \"rate_limit\" in str(e) or \"429\" in str(e):\n",
    "            print(f\"âš ï¸ ì¿¼í„° ì´ˆê³¼: {str(e)}\")\n",
    "            return False\n",
    "        else:\n",
    "            print(f\"âŒ ë‹¤ë¥¸ ì—ëŸ¬: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "def wait_for_quota_reset(wait_minutes=5):\n",
    "    \"\"\"\n",
    "    ì¿¼í„° ë¦¬ì…‹ ëŒ€ê¸°\n",
    "    \"\"\"\n",
    "    print(f\"â³ {wait_minutes}ë¶„ ëŒ€ê¸° ì¤‘...\")\n",
    "    time.sleep(wait_minutes * 60)\n",
    "    print(\"âœ… ëŒ€ê¸° ì™„ë£Œ!\")\n",
    "\n",
    "def safe_api_call(func, max_retries=3, wait_minutes=5):\n",
    "    \"\"\"\n",
    "    ì•ˆì „í•œ API í˜¸ì¶œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            return func()\n",
    "        except Exception as e:\n",
    "            if \"rate_limit\" in str(e) or \"429\" in str(e):\n",
    "                print(f\"âš ï¸ ì‹œë„ {attempt + 1}/{max_retries}: ì¿¼í„° ì´ˆê³¼\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_for_quota_reset(wait_minutes)\n",
    "                else:\n",
    "                    raise e\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "def run_self_consistency_test_with_quota_check(prompt: str, dataset, \n",
    "                                              model=\"llama3-8b-8192\", \n",
    "                                              num_samples=50, n=3, batch_size=10):\n",
    "    \"\"\"\n",
    "    Self-Consistency + ì¿¼í„° ì²´í¬ (ë°°ì¹˜ ì²˜ë¦¬)\n",
    "    \n",
    "    Args:\n",
    "        prompt: í”„ë¡¬í”„íŠ¸\n",
    "        dataset: í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹\n",
    "        model: ëª¨ë¸ëª…\n",
    "        num_samples: í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜\n",
    "        n: Self-Consistency ë°˜ë³µ íšŸìˆ˜\n",
    "        batch_size: ë°°ì¹˜ í¬ê¸°\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    correct = 0\n",
    "    \n",
    "    # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬\n",
    "    for batch_start in tqdm(range(0, num_samples, batch_size), desc=\"Batch Progress\"):\n",
    "        batch_end = min(batch_start + batch_size, num_samples)\n",
    "        \n",
    "        # ë°°ì¹˜ ì‹œì‘ ì „ ì¿¼í„° ì²´í¬\n",
    "        if not check_quota_usage():\n",
    "            print(f\"â¸ï¸ ë°°ì¹˜ {batch_start//batch_size + 1} ì‹œì‘ ì „ ì¿¼í„° ì²´í¬ ì‹¤íŒ¨\")\n",
    "            wait_for_quota_reset(5)\n",
    "        \n",
    "        # ë°°ì¹˜ ì²˜ë¦¬\n",
    "        for i in range(batch_start, batch_end):\n",
    "            q = dataset['question'][i]\n",
    "            a = dataset['answer'][i].split(\"####\")[-1].strip()\n",
    "            filled_prompt = prompt.replace(\"{question}\", q)\n",
    "\n",
    "            answers = []\n",
    "            for _ in range(n):\n",
    "                def api_call():\n",
    "                    return generate_response_using_Llama(filled_prompt, model=model)\n",
    "                \n",
    "                response = safe_api_call(api_call)\n",
    "                final = extract_final_answer(response)\n",
    "                answers.append(final)\n",
    "\n",
    "            most_common = Counter(answers).most_common(1)[0][0]\n",
    "\n",
    "            results.append({\n",
    "                \"question\": q,\n",
    "                \"correct_answer\": a,\n",
    "                \"predicted_answer\": most_common,\n",
    "                \"correct\": most_common == a\n",
    "            })\n",
    "\n",
    "            if most_common == a:\n",
    "                correct += 1\n",
    "        \n",
    "        # ë°°ì¹˜ ì™„ë£Œ í›„ ì§„í–‰ìƒí™© ì¶œë ¥\n",
    "        current_acc = correct / len(results) if results else 0\n",
    "        print(f\"ğŸ“Š ë°°ì¹˜ {batch_start//batch_size + 1} ì™„ë£Œ: [{len(results)}/{num_samples}] ì •í™•ë„: {current_acc:.2%}\")\n",
    "        \n",
    "        # ë°°ì¹˜ ê°„ ëŒ€ê¸°\n",
    "        if batch_end < num_samples:\n",
    "            time.sleep(2)\n",
    "\n",
    "    accuracy = correct / num_samples\n",
    "    return results, accuracy\n",
    "\n",
    "def run_self_consistency_test(prompt: str, dataset, \n",
    "                             model=\"llama3-8b-8192\", \n",
    "                             num_samples=50, n=3):\n",
    "    \"\"\"\n",
    "    ê¸°ë³¸ Self-Consistency í…ŒìŠ¤íŠ¸ (ì¿¼í„° ì²´í¬ ì—†ìŒ)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    correct = 0\n",
    "\n",
    "    for i in tqdm(range(num_samples), desc=\"Self-Consistency Progress\"):\n",
    "        q = dataset['question'][i]\n",
    "        a = dataset['answer'][i].split(\"####\")[-1].strip()\n",
    "        filled_prompt = prompt.replace(\"{question}\", q)\n",
    "\n",
    "        answers = []\n",
    "        for _ in range(n):\n",
    "            response = generate_response_using_Llama(filled_prompt, model=model)\n",
    "            final = extract_final_answer(response)\n",
    "            answers.append(final)\n",
    "\n",
    "        most_common = Counter(answers).most_common(1)[0][0]\n",
    "\n",
    "        results.append({\n",
    "            \"question\": q,\n",
    "            \"correct_answer\": a,\n",
    "            \"predicted_answer\": most_common,\n",
    "            \"correct\": most_common == a\n",
    "        })\n",
    "\n",
    "        if most_common == a:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / num_samples\n",
    "    return results, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ac2b0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing My Prompting with 0-shot + Self-Consistency...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Progress:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ë°°ì¹˜ 1 ì™„ë£Œ: [10/50] ì •í™•ë„: 80.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Progress:  20%|â–ˆâ–ˆ        | 1/5 [00:21<01:25, 21.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ë°°ì¹˜ 2 ì™„ë£Œ: [20/50] ì •í™•ë„: 70.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:53<03:09, 63.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ë°°ì¹˜ 3 ì™„ë£Œ: [30/50] ì •í™•ë„: 66.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [03:17<02:25, 72.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ë°°ì¹˜ 4 ì™„ë£Œ: [40/50] ì •í™•ë„: 67.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [06:04<00:00, 72.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ë°°ì¹˜ 5 ì™„ë£Œ: [50/50] ì •í™•ë„: 68.00%\n",
      "Accuracy: 68.00%\n",
      "\n",
      "Testing My Prompting with 3-shot + Self-Consistency...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Progress:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ë°°ì¹˜ 1 ì™„ë£Œ: [10/50] ì •í™•ë„: 60.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Progress:  20%|â–ˆâ–ˆ        | 1/5 [03:57<15:49, 237.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ë°°ì¹˜ 2 ì™„ë£Œ: [20/50] ì •í™•ë„: 65.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [08:09<12:17, 245.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ë°°ì¹˜ 3 ì™„ë£Œ: [30/50] ì •í™•ë„: 70.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [12:04<08:02, 241.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ë°°ì¹˜ 4 ì™„ë£Œ: [40/50] ì •í™•ë„: 70.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [20:11<00:00, 242.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ë°°ì¹˜ 5 ì™„ë£Œ: [50/50] ì •í™•ë„: 72.00%\n",
      "Accuracy: 72.00%\n",
      "\n",
      "Testing My Prompting with 5-shot + Self-Consistency...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Progress:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ë°°ì¹˜ 1 ì™„ë£Œ: [10/50] ì •í™•ë„: 70.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Progress:  20%|â–ˆâ–ˆ        | 1/5 [06:15<25:02, 375.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ë°°ì¹˜ 2 ì™„ë£Œ: [20/50] ì •í™•ë„: 70.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [12:40<19:03, 381.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ë°°ì¹˜ 3 ì™„ë£Œ: [30/50] ì •í™•ë„: 70.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [18:52<12:33, 376.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ë°°ì¹˜ 4 ì™„ë£Œ: [40/50] ì •í™•ë„: 70.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [31:22<00:00, 376.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ë°°ì¹˜ 5 ì™„ë£Œ: [50/50] ì •í™•ë„: 72.00%\n",
      "Accuracy: 72.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: ë§Œë“  0 shot, 3 shot, 5 shot exampleê³¼ í”„ë¡¬í”„íŠ¸ë¥¼ í†µí•´ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ë¥¼ í•œ í›„, ê°ê° My_prompting_{shot: int}.txtë¡œ ì €ì¥í•´ì£¼ì„¸ìš”!\n",
    "# ì˜ˆì‹œ: shotì´ 5ì¸ ê²½ìš° My_prompting_5.txt\n",
    "# í•­ìƒ num_samples=50 ì…ë‹ˆë‹¤!\n",
    "\n",
    "shots = [0, 3, 5]\n",
    "for shot in shots:\n",
    "    print(f\"Testing My Prompting with {shot}-shot + Self-Consistency...\")\n",
    "    PROMPT = construct_my_prompt(shot)\n",
    "    \n",
    "    # ì¿¼í„° ì²´í¬ ë²„ì „ ì‚¬ìš©\n",
    "    results, accuracy = run_self_consistency_test_with_quota_check(\n",
    "        prompt=PROMPT,\n",
    "        dataset=gsm8k_test,\n",
    "        model=\"llama3-8b-8192\",\n",
    "        num_samples=50,\n",
    "        n=3,\n",
    "        batch_size=10\n",
    "    )\n",
    "    \n",
    "    save_final_result(results, accuracy, f\"My_prompting_{shot}.txt\")\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd837d7",
   "metadata": {},
   "source": [
    "### ë³´ê³ ì„œ ì‘ì„±í•˜ê¸°\n",
    "#### ì•„ë˜ì˜ ë‚´ìš©ì´ í¬í•¨ë˜ë©´ ë©ë‹ˆë‹¤!\n",
    "\n",
    "1. Direct Prompting, CoT Prompting, My Promptingì„ 0 shot, 3 shot, 5 shot ì •ë‹µë¥ ì„ í‘œë¡œ ë³´ì—¬ì£¼ì„¸ìš”!\n",
    "2. CoT Promptingì´ Direct Promptingì— ë¹„í•´ ì™œ ì¢‹ì„ ìˆ˜ ìˆëŠ”ì§€ì— ëŒ€í•´ì„œ ì„œìˆ í•´ì£¼ì„¸ìš”!\n",
    "3. ë³¸ì¸ì´ ì‘ì„±í•œ í”„ë¡¬í”„íŠ¸ ê¸°ë²•ì´ CoTì— ë¹„í•´ì„œ ì™œ ë” ì¢‹ì„ ìˆ˜ ìˆëŠ”ì§€ì— ëŒ€í•´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”!\n",
    "4. ìµœì¢…ì ìœ¼ë¡œ, `PROMPTING.md`ì— ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03eb3b7e",
   "metadata": {},
   "source": [
    "## ğŸ“Š ì •ë‹µë¥  ë¹„êµ (0-shot, 3-shot, 5-shot)\n",
    "| Prompting ê¸°ë²•     | 0-shot | 3-shot | 5-shot |\n",
    "| ---------------- | ------ | ------ | ------ |\n",
    "| Direct Prompting | 18.00% | 20.00% | 16.00% |\n",
    "| CoT Prompting    | 58.00% | 70.00% | 70.00% |\n",
    "| My Prompting     | 68.00% | 72.00% | 72.00% |\n",
    "\n",
    "\n",
    "## ğŸ” CoT Promptingì´ Direct Promptingë³´ë‹¤ ë›°ì–´ë‚œ ì´ìœ \n",
    "\n",
    "Chain of Thought Prompting(CoT)ì€ ë¬¸ì œ í•´ê²° ê³¼ì •ì„ ë‹¨ê³„ì ìœ¼ë¡œ ì„œìˆ í•˜ê²Œ ë§Œë“¤ì–´, ë‹¨ìˆœí•œ ì •ë‹µ ì¶”ë¡ ë³´ë‹¤ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ìœ ë„\n",
    "íŠ¹íˆ ìˆ˜í•™ ë¬¸ì œì²˜ëŸ¼ ì¤‘ê°„ ê³„ì‚°ì´ í•„ìš”í•œ ë¬¸ì œì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ ì¥ì ì„ ê°€ì§\n",
    "- ì‚¬ê³  ê³¼ì •ì„ ë¶„í•´í•˜ì—¬ ë…¼ë¦¬ ì „ê°œ ê°€ëŠ¥\n",
    "- ì¤‘ê°„ ì¶”ë¡  ì˜¤ë¥˜ë¥¼ ë°©ì§€í•  ìˆ˜ ìˆìŒ\n",
    "- ë‹¤ë‹¨ê³„ ì‚¬ê³ (Multi-hop reasoning)ì— ì í•©í•¨\n",
    "\n",
    "**ì˜ˆì‹œ (CoT Prompting)**\n",
    "\n",
    "```\n",
    "Q: If a bag has 3 apples and each apple costs 2 dollars, how much is the total?\n",
    "A: There are 3 apples. Each costs 2 dollars. So, 3 Ã— 2 = 6.\n",
    "#### 6\n",
    "```\n",
    "\n",
    "**ì˜ˆì‹œ (Direct Prompting)**\n",
    "\n",
    "```\n",
    "Q: If a bag has 3 apples and each apple costs 2 dollars, how much is the total?\n",
    "A: 6\n",
    "```\n",
    "\n",
    "## ğŸ§ª My Promptingì´ CoTë³´ë‹¤ ë” ë‚˜ì€ ì´ìœ \n",
    "1. `â†’` ê¸°í˜¸ë¥¼ ì‚¬ìš©í•´ reasoning ë‹¨ê³„ ì‹œê°í™”\n",
    "2. ì„¤ëª…ì„ ìˆ˜ì‹ ìœ„ì£¼ë¡œ êµ¬ì„±í•´ í•µì‹¬ ì •ë³´ë§Œ ì „ë‹¬\n",
    "3. ì¼ê´€ëœ Q/A í˜•ì‹ ìœ ì§€ë¡œ ëª¨ë¸ í˜¼ë€ ìµœì†Œí™”\n",
    "4. Self-Consistency votingê³¼ ì˜ ì–´ìš¸ë¦¬ë„ë¡ êµ¬ì„±\n",
    "\n",
    "íŠ¹íˆ ì •ë‹µì„ í•˜ë‚˜ë§Œ ìƒì„±í•˜ëŠ” ëŒ€ì‹  ê°™ì€ ë¬¸ì œì— ëŒ€í•´ ì—¬ëŸ¬ ë²ˆ ì‘ë‹µì„ ìƒì„±í•˜ê³ , ê°€ì¥ ë§ì´ ë“±ì¥í•œ ë‹µì„ ìµœì¢… ì •ë‹µìœ¼ë¡œ ì±„íƒí•˜ëŠ” ë°©ì‹(Self-Consistency)ì„ ë„ì…í•¨\n",
    "ì´ë¥¼ í†µí•´,\n",
    "- ë¶ˆí™•ì‹¤í•œ ì¶”ë¡ ì— ëŒ€í•œ ì•ˆì •ì„± ì¦ê°€\n",
    "- ë³µì¡í•œ ë¬¸ì œì— ëŒ€í•œ í‰ê·œì  ì‚¬ê³  ëŠ¥ë ¥ ê°•í™”\n",
    "ë¥¼ ê¸°ëŒ€í•  ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "**ì˜ˆì‹œ (My Prompting)**\n",
    "\n",
    "```\n",
    "Q: If a bag has 3 apples and each apple costs 2 dollars, how much is the total?\n",
    "A: â†’ Apples: 3  \n",
    "â†’ Cost per apple: 2  \n",
    "â†’ Total = 3 Ã— 2 = 6  \n",
    "#### 6\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609a00d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ybigta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
